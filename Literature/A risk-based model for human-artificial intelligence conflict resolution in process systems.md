---
tags:
  - "#literature"
title: A risk-based model for human-artificial intelligence conflict resolution in process systems
author: He Wen, Faisal Khan
year: 2024
link: https://www.sciencedirect.com/science/article/pii/S2772508124000565
---
# Take Away Points
- 

# Summary
The paper proposes a model to quantify and resolve conflicts which result from discrepancies in human and AI observation, interpretation, and action. The mathematical model is based on conventional human conflict resolution mechanisms. The authors claim the model promotes human-AI collaboration with real-time response to human input. 
## Introduction
Although AI has developed human-like skills, their decision making deviates from human expectations. This phenomenon is described as human-AI conflict, which can often be "mistakenly interpreted as faults, failures, or cyberattacks". Because of the anthropomorphic characteristics  of AI decision making, a potential solution could be to use human-human conflict resolutions models such as  the Thomas-Kilmann Instrument (TKI). Currently, control systems "lack the capability to perceive and integrate human observations and actions with the data they collect", which prevents human-AI collaboration in their use cases. With this problem in mind, the paper seeks to address four problems:

1) How to best mathematically represent the evolving conflict between humans and AI?
2) What are the strategies of conflict resolution?
3) How do we measure the conflict risk and link it to resolution strategies?
4) How do we adapt the well-established social conflict resolution strategies to human-AI conflict resolution?

## Methodology
Adapts the TKI model as a risk model. Comprised of three steps

1) Construct the conflict risk representations by measuring the agreement level of interpretations and actions.
2) Propose mathematical equations to measure conflict probability
3) Develop conflict resolution strategies by minimizing the conflict risk.

## The Model
Generally, the model lies on a two axis plane, where the $x$ is the agreement of interpretation and $y$ is agreement of actions. The model proposes a vector for the human $(x_h, y_h)$ and a vector for the AI $(x_a, y_a)$. The angle between these two vectors $\Delta \theta$ is correlated to the probability of conflict, and the difference in magnitude $\Delta y$ is correlated to the severity of a potential conflict. 

# Models, Datasets, Algorithms

