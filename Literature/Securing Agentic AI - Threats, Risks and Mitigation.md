---
tags:
  - "#literature"
title: Securing Agentic AI - Threats, Risks and Mitigation
author: S M Zia Ur Rashid, Irfanul Montasir, Ashfaqul Haq
year: 2025
link: https://www.researchgate.net/profile/S-M-Zia-Ur-Rashid/publication/388493552_Securing_Agentic_AI_Threats_Risks_and_Mitigation/links/679ad00352b58d39f25b9aad/Securing-Agentic-AI-Threats-Risks-and-Mitigation.pdf
---
# Introduction
The paper identifies potential securities risks that arise from the increased use of AI in enterprise applications. The paper seeks to lays these risks out to lay the groundwork for further research in the topic. 

# Attack Vectors
## Hallucination Exploitation
Adversaries may make AI suggest or provide suggestions which lead to security risks. For example, the AI may suggest the use of non-existent software library. An attacker may develop an interface under this name and have it integrated into the system, potentially giving the attacker access servers or back end systems. 

## Knowledge Base Poisoning
Internal or external attackers could feed AI " contaminated or detrimental data into the knowledge base so that it produces wrong or unsolicited outcomes.". This could result in exploitable vulnerabilities in the platforms or result in altered AI agent behavior in systems. 

## Goal and Instruction Manipulation


## Jailbreaking and Control Hijacking
Attackers could use prompts that bypass the security measures and restrictions placed on an AI model. This can allow the attacker to execute unlawful commands. This would allow 