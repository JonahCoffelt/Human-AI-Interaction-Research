# Introduction
Advances in AI models and techniques has lead to an increased adoption of AI in industry. Most notably, LLMs exhibit impressive observation, interpretation, reasoning, and decision making abilities. With these developments in human-like skills, AI is being used for many applications across various fields with increased autonomy and integration into workflows. These workflows often include both human and AI agents, requiring interaction between the two. These interactions create novel conflicts which must be taken into consideration when designing, managing, and operating workflows. 

We define a workflow as a series of tasks performed in sequence or parallel aimed at a particular goal. A workflow is considered effective if it satisfies the goal and abides by necessary constraints; it is more efficient if it is able to do all this faster or cheaper. Additionally, we would consider a workflow resilient if it is able to withstand potential intermediate failures while still satisfying the goal. Effectiveness, efficiency, and reliability can all be fine tuned through the design of a workflow. For example, the reliability of a workflow could be improved by adding redundancy, but this would come at the cost of efficiency.

The tasks of a workflow are completed by agents. An agent is a person or thing that takes autonomous physical or symbolic actions, resulting in an effect in a particular environment. For the purposes of this paper, an agent may be one of two types: human or AI. Within these broad categorizations, there are various degrees and areas of expertise between individual agents. The expertise and reliability of an agent should be taken into consideration when employing the agent for a particular task.

Our aim is to mitigate the risk of conflict in human-AI workflows by curating the design and topology of the workflow to be intuitively effective, efficient, and reliable given the involved agents and goal. This aim is twofold: The solution should minimize human-AI conflict both on the governance and operation levels. Humans should have sufficient priority in the design of the workflow and significant roles in the execution of the workflow. The workflow should maximize collaboration and minimize competition between agents.

# Background
The potential for human-AI conflict has not gone unnoticed in the literature. Wen and Khan developed a framework for representing human-AI conflict and developing strategies for minimizing the associated risks. They claimed that conflicts arise as a result of differences in observation, interpretation, and action. Their model was based on an existing human-human conflict resolution model, namely the TKI model. The model quantified the agreement of interpretation and agreement of action as vectors. From this, they determined the probability and severity of a conflict based on the difference in agreement vectors. Finally, they defined the risk of conflict as the sum of probability and severity. Through applying their model, they identify the importance of human input in human-AI systems.

Recent work on AI systems has heavy emphasis on a multi-agent approach. Many frameworks, such as AutoGen, MetaGPT, and CAMEL have been used to make larger more complex multi-agent AI workflows that can handle larger goals and combat hallucinations. Flow is an approach for generating dynamically updated modular workflows that maximize parallelism and minimize dependency complexity. 